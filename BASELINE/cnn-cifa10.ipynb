{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CNN with CIFAR10","metadata":{"id":"Bsgd250HwzNl"}},{"cell_type":"markdown","source":"CIFAR 10은 컬러 데이터로, MNIST와는 다르게 channel이 3개가 됩니다.\n\nCIFAR 10부터는 GPU 변경을 해주시는 것을 추천드립니다.\n\n## 과제 설명\n\n아래 물음표로 되어 있는 곳을 채워서 제출하시고, 다양한 hyperparameter 변경, 혹은 다양한 기법을 통해서 성능을 높이는 것이 최종 목표입니다.\n물론, 수업 시간에 진행한 VGG만큼의 성능은 얻을 수 없지만, 최대한 다양한 방법을 통해 성능을 높여서 제출해주세요.\n\n4월 19일 수요일 자정까지 CNN, 그리고 추가적으로 배울 GAN 모델을 CIFAR-10에 대해서 구현해보는 것이 목표입니다.\n과제: 공지드린 바와 같이 이번주 과제는 ML_Day4_1, ML_Day4_2 파일의 빈칸을 완성하여 ds.slcf@gmail.com으로 제출해주시면 됩니다.\n과제 혹은 강의 내용 관련 문의사항이 있으실 경우 자유롭게 문의 주시기 바랍니다!","metadata":{"id":"TVssPUy5w2eN"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nimport torchvision.utils\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\n\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"ouDP37idwzNt","execution":{"iopub.status.busy":"2023-04-19T13:14:33.854648Z","iopub.execute_input":"2023-04-19T13:14:33.855532Z","iopub.status.idle":"2023-04-19T13:14:33.862084Z","shell.execute_reply.started":"2023-04-19T13:14:33.855493Z","shell.execute_reply":"2023-04-19T13:14:33.860506Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n# Define the normalization statistics\nstats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n# Define the data transforms for the training set\ntrain_tfms = transforms.Compose([\n    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(*stats)\n])\n# Define the data transforms for the validation/test set\nvalid_tfms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(*stats)\n])\n# Load the CIFAR10 training set\ntrain_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tfms)\n# Load the CIFAR10 validation/test set\ntest_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=valid_tfms)\n\nfrom torch.utils.data import random_split\nbatch_size = 128\n# Define the size of the validation set as a percentage of the total dataset\nval_size = 0.2\n# Calculate the size of the validation set based on the validation size and the total size of the dataset\nnum_train = len(train_data)\nnum_val = int(val_size * num_train)\n# Split the training set into a training set and a validation set\ntrain_data, val_data = random_split(train_data, [num_train - num_val, num_val])\n# Create data loaders for the training, validation, and test sets\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_data, batch_size=5, shuffle=False)\n# Define the class labels\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3urv48_nGdx","outputId":"8c8603ef-7eb9-4d8a-f157-8e33ba6733e5","execution":{"iopub.status.busy":"2023-04-19T13:14:54.724938Z","iopub.execute_input":"2023-04-19T13:14:54.726174Z","iopub.status.idle":"2023-04-19T13:14:56.367636Z","shell.execute_reply.started":"2023-04-19T13:14:54.726125Z","shell.execute_reply":"2023-04-19T13:14:56.366529Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 이번에는 직접 모델을 만들어 보도록 하겠습니다.\n\nMNIST 실습파일과는 다르게 정답이 정해지지 않았으며, 오류가 나지 않도록 원하시는 대로 숫자를 넣어 코드를 돌리고 제출해주세요!","metadata":{"id":"v-aKayRKwzN6"}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n\n        self.conv_layer = nn.Sequential(\n            nn.Conv2d(3, 16, 3, padding=1),  # 32x32x3 -> 32x32x16\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Conv2d(16, 32, 3, padding=1),  # 32x32x16 -> 32x32x32\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Conv2d(32, 64, 3, padding=1),  # 32x32x32 -> 32x32x64\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Conv2d(64, 128, 3, padding=1),  # 32x32x64 -> 32x32x128\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Conv2d(128, 256, 3, padding=1),  # 32x32x128 -> 32x32x256\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.MaxPool2d(2, 2),  # 32x32x256 -> 16x16x256\n            nn.Conv2d(256, 512, 3, padding=1),  # 16x16x256 -> 16x16x512\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Conv2d(512, 1024, 3, padding=1),  # 16x16x512 -> 16x16x1024\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.MaxPool2d(2, 2),  # 16x16x1024 -> 8x8x1024\n            nn.Conv2d(1024, 2048, 3, padding=1),  # 8x8x1024 -> 8x8x2048\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.MaxPool2d(2, 2)  # 8x8x2048 -> 4x4x2048\n        )\n\n        self.fc_layer = nn.Sequential(\n            nn.Linear(4*4*2048, 512),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        out = self.conv_layer(x)\n        out = out.view(-1, 4*4*2048)\n        out = self.fc_layer(out)\n\n        return out\n","metadata":{"id":"lkIBXY25MqYL","execution":{"iopub.status.busy":"2023-04-19T13:15:55.054362Z","iopub.execute_input":"2023-04-19T13:15:55.055057Z","iopub.status.idle":"2023-04-19T13:15:55.067270Z","shell.execute_reply.started":"2023-04-19T13:15:55.055020Z","shell.execute_reply":"2023-04-19T13:15:55.066036Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = CNN().cuda()","metadata":{"id":"t3sbQ6N054_d","execution":{"iopub.status.busy":"2023-04-19T13:16:00.318236Z","iopub.execute_input":"2023-04-19T13:16:00.318627Z","iopub.status.idle":"2023-04-19T13:16:05.168111Z","shell.execute_reply.started":"2023-04-19T13:16:00.318590Z","shell.execute_reply":"2023-04-19T13:16:05.167039Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"loss = nn.CrossEntropyLoss()\n# optimizer = optim.SGD(model.parameters(), lr=0.01)\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)","metadata":{"id":"_T6XREcSwzN8","execution":{"iopub.status.busy":"2023-04-19T13:16:10.835017Z","iopub.execute_input":"2023-04-19T13:16:10.835383Z","iopub.status.idle":"2023-04-19T13:16:10.840941Z","shell.execute_reply.started":"2023-04-19T13:16:10.835350Z","shell.execute_reply":"2023-04-19T13:16:10.839763Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 14.3 Train Model","metadata":{"id":"mYJPuaNvwzN9"}},{"cell_type":"code","source":"## val loss 까지 계산 -> overfitting 확인용\n\nnum_epochs = 40\nbatch_size = 200\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n\nfor epoch in range(num_epochs):\n\n    # Train\n    model.train()\n    train_loss = 0.0\n    total_batch = len(train_data) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        \n        X = batch_images.cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(X)\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        train_loss += cost.item()\n\n        if (i+1) % 200 == 0:\n            print('Epoch [%d/%d], Train Iter [%d/%d], Train Loss: %.4f'\n                 %(epoch+1, num_epochs, i+1, total_batch, train_loss/200))\n            train_loss = 0.0\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for batch_images, batch_labels in val_loader:\n            X = batch_images.cuda()\n            Y = batch_labels.cuda()\n\n            pre = model(X)\n            cost = loss(pre, Y)\n\n            val_loss += cost.item()\n\n    val_loss /= len(val_loader)\n    print('Epoch [%d/%d], Validation Loss: %.4f' %(epoch+1, num_epochs, val_loss))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viAQwW7zW_N6","outputId":"dc8f2e05-e2b7-4ee9-cd2a-3195fd431895","execution":{"iopub.status.busy":"2023-04-19T13:16:47.629260Z","iopub.execute_input":"2023-04-19T13:16:47.630236Z","iopub.status.idle":"2023-04-19T14:28:52.211308Z","shell.execute_reply.started":"2023-04-19T13:16:47.630194Z","shell.execute_reply":"2023-04-19T14:28:52.210075Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch [1/40], Train Iter [200/200], Train Loss: 2.0901\nEpoch [1/40], Validation Loss: 1.8202\nEpoch [2/40], Train Iter [200/200], Train Loss: 1.6737\nEpoch [2/40], Validation Loss: 1.5831\nEpoch [3/40], Train Iter [200/200], Train Loss: 1.4770\nEpoch [3/40], Validation Loss: 1.4015\nEpoch [4/40], Train Iter [200/200], Train Loss: 1.3402\nEpoch [4/40], Validation Loss: 1.2837\nEpoch [5/40], Train Iter [200/200], Train Loss: 1.2246\nEpoch [5/40], Validation Loss: 1.2245\nEpoch [6/40], Train Iter [200/200], Train Loss: 1.1416\nEpoch [6/40], Validation Loss: 1.1100\nEpoch [7/40], Train Iter [200/200], Train Loss: 1.0614\nEpoch [7/40], Validation Loss: 1.0334\nEpoch [8/40], Train Iter [200/200], Train Loss: 0.9992\nEpoch [8/40], Validation Loss: 0.9639\nEpoch [9/40], Train Iter [200/200], Train Loss: 0.9449\nEpoch [9/40], Validation Loss: 0.9067\nEpoch [10/40], Train Iter [200/200], Train Loss: 0.8916\nEpoch [10/40], Validation Loss: 0.8393\nEpoch [11/40], Train Iter [200/200], Train Loss: 0.8388\nEpoch [11/40], Validation Loss: 0.8217\nEpoch [12/40], Train Iter [200/200], Train Loss: 0.7902\nEpoch [12/40], Validation Loss: 0.7568\nEpoch [13/40], Train Iter [200/200], Train Loss: 0.7570\nEpoch [13/40], Validation Loss: 0.7349\nEpoch [14/40], Train Iter [200/200], Train Loss: 0.7227\nEpoch [14/40], Validation Loss: 0.7248\nEpoch [15/40], Train Iter [200/200], Train Loss: 0.7015\nEpoch [15/40], Validation Loss: 0.6835\nEpoch [16/40], Train Iter [200/200], Train Loss: 0.6733\nEpoch [16/40], Validation Loss: 0.6841\nEpoch [17/40], Train Iter [200/200], Train Loss: 0.6553\nEpoch [17/40], Validation Loss: 0.6539\nEpoch [18/40], Train Iter [200/200], Train Loss: 0.6354\nEpoch [18/40], Validation Loss: 0.6349\nEpoch [19/40], Train Iter [200/200], Train Loss: 0.6171\nEpoch [19/40], Validation Loss: 0.6001\nEpoch [20/40], Train Iter [200/200], Train Loss: 0.5985\nEpoch [20/40], Validation Loss: 0.6031\nEpoch [21/40], Train Iter [200/200], Train Loss: 0.5844\nEpoch [21/40], Validation Loss: 0.5856\nEpoch [22/40], Train Iter [200/200], Train Loss: 0.5828\nEpoch [22/40], Validation Loss: 0.5807\nEpoch [23/40], Train Iter [200/200], Train Loss: 0.5533\nEpoch [23/40], Validation Loss: 0.5542\nEpoch [24/40], Train Iter [200/200], Train Loss: 0.5503\nEpoch [24/40], Validation Loss: 0.5475\nEpoch [25/40], Train Iter [200/200], Train Loss: 0.5358\nEpoch [25/40], Validation Loss: 0.5498\nEpoch [26/40], Train Iter [200/200], Train Loss: 0.5310\nEpoch [26/40], Validation Loss: 0.5399\nEpoch [27/40], Train Iter [200/200], Train Loss: 0.5264\nEpoch [27/40], Validation Loss: 0.5468\nEpoch [28/40], Train Iter [200/200], Train Loss: 0.5162\nEpoch [28/40], Validation Loss: 0.5485\nEpoch [29/40], Train Iter [200/200], Train Loss: 0.5064\nEpoch [29/40], Validation Loss: 0.5156\nEpoch [30/40], Train Iter [200/200], Train Loss: 0.4883\nEpoch [30/40], Validation Loss: 0.4833\nEpoch [31/40], Train Iter [200/200], Train Loss: 0.4899\nEpoch [31/40], Validation Loss: 0.5094\nEpoch [32/40], Train Iter [200/200], Train Loss: 0.4802\nEpoch [32/40], Validation Loss: 0.4858\nEpoch [33/40], Train Iter [200/200], Train Loss: 0.4736\nEpoch [33/40], Validation Loss: 0.5314\nEpoch [34/40], Train Iter [200/200], Train Loss: 0.4748\nEpoch [34/40], Validation Loss: 0.4732\nEpoch [35/40], Train Iter [200/200], Train Loss: 0.4652\nEpoch [35/40], Validation Loss: 0.4845\nEpoch [36/40], Train Iter [200/200], Train Loss: 0.4608\nEpoch [36/40], Validation Loss: 0.4963\nEpoch [37/40], Train Iter [200/200], Train Loss: 0.4561\nEpoch [37/40], Validation Loss: 0.4636\nEpoch [38/40], Train Iter [200/200], Train Loss: 0.4525\nEpoch [38/40], Validation Loss: 0.4806\nEpoch [39/40], Train Iter [200/200], Train Loss: 0.4376\nEpoch [39/40], Validation Loss: 0.4552\nEpoch [40/40], Train Iter [200/200], Train Loss: 0.4358\nEpoch [40/40], Validation Loss: 0.4705\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 14.4 Test Model","metadata":{"id":"wJWjo3zgwzN_"}},{"cell_type":"code","source":"correct = 0\ntotal = 0\nmodel.eval() # 검증 모드 \nwith torch.no_grad(): # 역전파 x\n\n    for images, labels in test_loader:\n\n        images = images.cuda()\n        outputs = model(images)\n\n        _, predicted = torch.max(outputs.data, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels.cuda()).sum()\n\nprint('Accuracy of test images: %f %%' % (100 * float(correct) / total))","metadata":{"id":"Wexq9V4NwzN_","execution":{"iopub.status.busy":"2023-04-19T14:28:52.220943Z","iopub.execute_input":"2023-04-19T14:28:52.221305Z","iopub.status.idle":"2023-04-19T14:29:12.345701Z","shell.execute_reply.started":"2023-04-19T14:28:52.221269Z","shell.execute_reply":"2023-04-19T14:29:12.344544Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy of test images: 85.720000 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}